# eval-skill

Give Claude a verification loop. Define acceptance criteria before implementation, let Claude check its own work.

## The Problem

> *"How will the agent know it did the right thing?"*
> â€” [Thorsten Ball](https://x.com/thorstenball)

Without verification, Claude implements and hopes. With verification, Claude implements and **knows**.

## The Solution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. SKILL: eval                                             â”‚
â”‚     "Create evals for auth"                                 â”‚
â”‚     â†’ Generates .claude/evals/auth.yaml                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. AGENT: eval-verifier                                    â”‚
â”‚     "/eval verify auth"                                     â”‚
â”‚     â†’ Runs checks                                           â”‚
â”‚     â†’ Collects evidence (screenshots, outputs)              â”‚
â”‚     â†’ Generates executable tests                            â”‚
â”‚     â†’ Reports pass/fail                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. OUTPUT                                                  â”‚
â”‚     .claude/evals/.evidence/auth/  â† Screenshots, logs      â”‚
â”‚     tests/generated/test_auth.py   â† Executable tests       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Install

```bash
git clone https://github.com/yourusername/eval-skill.git
cd eval-skill

# Install to current project
./install.sh

# Or install globally (all projects)
./install.sh --global
```

## Usage

### 1. Create Evals (Before Implementation)

```
> Create evals for user authentication
```

Claude generates `.claude/evals/auth.yaml`:

```yaml
name: auth
description: Email/password authentication

test_output:
  framework: pytest
  path: tests/generated/

verify:
  # Deterministic
  - type: command
    run: "npm test -- --grep 'auth'"
    expect: exit_code 0
    
  - type: file-contains
    path: src/auth/password.ts
    pattern: "bcrypt|argon2"

  # Agent-based (with evidence + test generation)
  - type: agent
    name: ui-login
    prompt: |
      1. Go to /login
      2. Enter test@example.com / password123
      3. Submit
      4. Verify redirect to /dashboard
    evidence:
      - screenshot: after-login
      - url: contains "/dashboard"
    generate_test: true
```

### 2. Implement

```
> Implement auth based on .claude/evals/auth.yaml
```

### 3. Verify

```
> /eval verify auth
```

Output:

```
ğŸ” Eval: auth
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Deterministic:
  âœ… command: npm test (exit 0)
  âœ… file-contains: bcrypt in password.ts

Agent:
  âœ… ui-login: Dashboard redirect works
     ğŸ“¸ Evidence: 2 screenshots saved
     ğŸ“„ Test: tests/generated/test_auth_ui_login.py

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š Results: 3/3 passed
```

### 4. Run Generated Tests (Forever)

```bash
pytest tests/generated/
```

The agent converted its semantic verification into deterministic tests.

## How It Works

### Non-Deterministic â†’ Deterministic

Agent checks are semantic: "verify login works." But we need proof.

1. **Verifier runs the check** (browser automation, API calls, file inspection)
2. **Collects evidence** (screenshots, responses, DOM snapshots)
3. **Generates executable test** (pytest/vitest)
4. **Future runs use the test** (no agent needed)

```
Agent Check (expensive)    â†’    Evidence (proof)    â†’    Test (cheap, repeatable)
     â†“                              â†“                          â†“
"Login works"              screenshot + url check      pytest + playwright
```

### Evidence-Based Verification

The verifier can't just say "pass." It must provide evidence:

```yaml
- type: agent
  name: login-flow
  prompt: "Verify login redirects to dashboard"
  evidence:
    - screenshot: login-page
    - screenshot: after-submit
    - url: contains "/dashboard"
    - element: '[data-testid="welcome"]'
```

Evidence is saved to `.claude/evals/.evidence/<eval>/`:

```json
{
  "eval": "auth",
  "checks": [{
    "name": "login-flow",
    "pass": true,
    "evidence": [
      {"type": "screenshot", "path": "login-page.png"},
      {"type": "screenshot", "path": "after-submit.png"},
      {"type": "url", "expected": "contains /dashboard", "actual": "http://localhost:3000/dashboard"},
      {"type": "element", "selector": "[data-testid=welcome]", "found": true}
    ]
  }]
}
```

## Check Types

### Deterministic (Fast, No Agent)

```yaml
# Command + exit code
- type: command
  run: "pytest tests/"
  expect: exit_code 0

# Command + output
- type: command
  run: "curl localhost:3000/health"
  expect:
    contains: '"status":"ok"'

# File exists
- type: file-exists
  path: src/feature.ts

# File contains pattern
- type: file-contains
  path: src/auth.ts
  pattern: "bcrypt"

# File does NOT contain
- type: file-not-contains
  path: .env
  pattern: "sk-"
```

### Agent (Semantic, Evidence-Based)

```yaml
- type: agent
  name: descriptive-name
  prompt: |
    Step-by-step verification instructions
  evidence:
    - screenshot: step-name
    - url: contains "pattern"
    - element: "css-selector"
    - text: "expected text"
    - response: status 200
  generate_test: true  # Write executable test
```

## Commands

| Command | Description |
|---------|-------------|
| `/eval list` | List all evals |
| `/eval show <name>` | Display eval spec |
| `/eval verify <name>` | Run verification |
| `/eval verify` | Run all evals |
| `/eval evidence <name>` | Show collected evidence |
| `/eval tests` | List generated tests |
| `/eval clean` | Remove evidence + generated tests |

## Directory Structure

```
.claude/
â”œâ”€â”€ skills/eval/SKILL.md       # Eval generation skill
â”œâ”€â”€ agents/eval-verifier.md    # Verification agent
â”œâ”€â”€ commands/eval.md           # /eval command
â””â”€â”€ evals/
    â”œâ”€â”€ auth.yaml              # Your eval specs
    â”œâ”€â”€ checkout.yaml
    â””â”€â”€ .evidence/
        â”œâ”€â”€ auth/
        â”‚   â”œâ”€â”€ evidence.json
        â”‚   â””â”€â”€ *.png
        â””â”€â”€ checkout/
            â””â”€â”€ ...

tests/
â””â”€â”€ generated/                  # Tests written by verifier
    â”œâ”€â”€ test_auth_ui_login.py
    â””â”€â”€ test_auth_api_login.py
```

## Requirements

- Claude Code with skills/agents/commands support
- For UI testing: `npm install -g @anthropic/agent-browser`

## Philosophy

**TDD for Agents:**

| Traditional TDD | Agent TDD |
|----------------|-----------|
| Write tests | Write evals |
| Write code | Claude writes code |
| Tests pass | Claude verifies + generates tests |

**Why generate tests?**

Agent verification is expensive (tokens, time). But once verified, we encode that verification as a test. Future runs use the test â€” no agent needed.

**Mix deterministic and semantic:**

- Deterministic: "tests pass", "file exists", "command succeeds"
- Semantic: "UI looks right", "error is helpful", "code is readable"

Use deterministic where possible, semantic where necessary.

## License

MIT
